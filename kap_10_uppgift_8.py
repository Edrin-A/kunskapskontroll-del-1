import streamlit as st
import numpy as np
from google import genai
from google.genai import types
from pypdf import PdfReader
from youtube_transcript_api import YouTubeTranscriptApi
import re
import os
import unicodedata
from dotenv import load_dotenv

load_dotenv()

def fix_swedish_chars(text):
    """Fixar vanliga svenska tecken som kan bli felkodade fr친n PDF."""
    # Hantera mellanrum mellan diakritiska tecken och bokst칛ver
    import re

    # Med eller utan mellanrum
    patterns = [
        (r'틬\s*a', '친'), (r'춷\s*a', '칛'), (r'춷\s*o', '칬'),
        (r'틬\s*A', '칀'), (r'춷\s*A', '츿'), (r'춷\s*O', '칐'),
        (r'췂\s*e', '칠'), (r'췂\s*E', '칄'),
    ]

    for pattern, replacement in patterns:
        text = re.sub(pattern, replacement, text)

    # Normalisera f칬rst med NFKD f칬r att separera, sedan NFC f칬r att kombinera
    text = unicodedata.normalize('NFKD', text)
    text = unicodedata.normalize('NFC', text)

    return text

# API-koppling
api_key = os.getenv("API_KEY")
client = genai.Client(api_key=api_key)

# Chunking
def chunk_text(text, chunk_size=1000, overlap=200):
    """Delar upp text i mindre bitar med 칬verlapp."""
    chunks = []
    for i in range(0, len(text), chunk_size - overlap):
        chunks.append(text[i:i + chunk_size])
    return chunks

# YouTube funktioner
def extract_video_id(url):
    """Extraherar video ID fr친n olika YouTube URL-format."""
    patterns = [
        r'(?:v=|\/)([0-9A-Za-z_-]{11}).*',
        r'(?:youtu\.be\/)([0-9A-Za-z_-]{11})',
        r'(?:embed\/)([0-9A-Za-z_-]{11})'
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

def get_youtube_transcript(video_url):
    """H칛mtar transkript fr친n en YouTube video."""
    video_id = extract_video_id(video_url)
    if not video_id:
        raise ValueError("Ogiltig YouTube-URL")

    try:
        # Skapa API instans
        ytt_api = YouTubeTranscriptApi()

        # F칬rs칬k h칛mta transkript med olika spr친k (svenska f칬rst, sedan engelska)
        languages_to_try = ['sv', 'en', 'en-US', 'en-GB']
        transcript = None

        for lang in languages_to_try:
            try:
                transcript = ytt_api.fetch(video_id, languages=[lang])
                break
            except:
                continue

        # Om inget spr친k fungerade, f칬rs칬k utan spr친kspecifikation
        if transcript is None:
            transcript = ytt_api.fetch(video_id)

        # Kombinera all text fr친n snippets
        full_text = " ".join([snippet.text for snippet in transcript.snippets])
        return full_text
    except Exception as e:
        raise ValueError(f"Kunde inte h칛mta transkript: {str(e)}")

# Embeddings
def create_embeddings(chunks, model="gemini-embedding-001", task_type="SEMANTIC_SIMILARITY"):
    """Skapar embeddings f칬r en lista av chunks. Hanterar API gr칛nsen p친 100 per batch."""
    all_embeddings = []
    batch_size = 100

    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i + batch_size]
        response = client.models.embed_content(
            model=model,
            contents=batch,
            config=types.EmbedContentConfig(task_type=task_type)
        )
        all_embeddings.extend(response.embeddings)

    return all_embeddings

def create_single_embedding(text, model="gemini-embedding-001", task_type="SEMANTIC_SIMILARITY"):
    """Skapar embedding f칬r en enskild text (t.ex. en fr친ga)."""
    response = client.models.embed_content(
        model=model,
        contents=text,
        config=types.EmbedContentConfig(task_type=task_type)
    )
    return response.embeddings[0].values

# Semantisk s칬kning
# Score kommer fr친n cosine similarity mellan embeddings, och visar hur semantiskt lik en textbit 칛r din fr친ga. Ju h칬gre procent, desto mer relevant 칛r chunken!
def cosine_similarity(vec1, vec2):
    """Ber칛knar cosine similarity mellan tv친 vektorer."""
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

def semantic_search(query, chunks, embeddings, k=5, relevance_threshold=0.5):
    """S칬ker efter de mest relevanta chunks baserat p친 fr친gan."""
    query_embedding = create_single_embedding(query)
    similarity_scores = []

    for i, chunk_embedding in enumerate(embeddings):
        similarity_score = cosine_similarity(query_embedding, chunk_embedding.values)
        similarity_scores.append((i, similarity_score))

    similarity_scores.sort(key=lambda x: x[1], reverse=True)

    # Filtrera p친 relevans tr칬skel och ta max k resultat
    filtered_results = [(i, score) for i, score in similarity_scores if score >= relevance_threshold]
    top_results = filtered_results[:k]

    return [(chunks[i], score) for i, score in top_results]

# Generera svar
SYSTEM_PROMPT = """Du 칛r en hj칛lpsam assistent som svarar p친 fr친gor baserat
p친 den kontext som ges. Du har tillg친ng till tidigare konversation f칬r att
kunna hantera uppf칬ljningsfr친gor.

Regler:
- Basera alltid dina svar p친 informationen i kontexten
- Du F칀R kombinera och dra slutsatser fr친n olika delar av kontexten
- N칛r du kombinerar information, var tydlig med vad som kommer fr친n vilken del
- Om svaret verkligen inte finns i kontexten, s칛g "Jag kan inte hitta svaret p친 den fr친gan i dokumentet"
- Hitta INTE P칀 information som inte finns i kontexten
- Var tydlig och strukturerad i dina svar
- Citera g칛rna relevanta delar fr친n kontexten n칛r det passar
- Svara p친 samma spr친k som fr친gan st칛lls p친
- Vid uppf칬ljningsfr친gor (t.ex. "kan du f칬rklara mer om det?"), anv칛nd tidigare konversation f칬r kontext
- Om anv칛ndaren s칛ger "det", "detta", etc., referera till tidigare diskussion
"""

def generate_response(query, chunks, embeddings, conversation_history=None, model="gemini-2.0-flash", relevance_threshold=0.5, max_chunks=5):
    """Genererar svar baserat p친 semantisk s칬kning i dokumentet."""
    # H칛mta relevanta chunks med scores och tr칬skel
    relevant_chunks = semantic_search(query, chunks, embeddings, k=max_chunks, relevance_threshold=relevance_threshold)

    # Kontrollera om vi har bra k칛llor
    low_relevance_warning = False
    if not relevant_chunks:
        # Inga chunks 칬ver threshold, anv칛nd top 3 칛nd친 men varna
        relevant_chunks = semantic_search(query, chunks, embeddings, k=3, relevance_threshold=0.0)
        low_relevance_warning = True
    elif relevant_chunks and relevant_chunks[0][1] < 0.65:
        # B칛sta tr칛ffen 칛r under 65%, m친ttlig varning
        low_relevance_warning = True

    # Bygg kontext fr친n chunks
    context = "\n\n".join([chunk for chunk, score in relevant_chunks])

    # Bygg conversation history om det finns
    history_text = ""
    if conversation_history and len(conversation_history) > 0:
        # Ta de senaste 4 meddelandena (2 Q&A par)
        recent_history = conversation_history[-4:]
        history_parts = []
        for msg in recent_history:
            role = "Anv칛ndare" if msg["role"] == "user" else "Assistent"
            history_parts.append(f"{role}: {msg['content']}")
        history_text = "\n".join(history_parts)

    # Skapa user prompt med eller utan historik
    if history_text:
        user_prompt = f"""Tidigare konversation:
{history_text}

Nuvarande fr친ga: {query}

H칛r 칛r relevant kontext fr친n dokumentet:
{context}"""
    else:
        user_prompt = f"Fr친gan 칛r: {query}\n\nH칛r 칛r kontexten:\n{context}"

    # Generera svar med l칛gre temperatur f칬r mer faktabaserade svar
    response = client.models.generate_content(
        model=model,
        config=genai.types.GenerateContentConfig(
            system_instruction=SYSTEM_PROMPT,
            temperature=0.3,  # L친g temperatur = mer faktabaserad
            top_p=0.8
        ),
        contents=user_prompt
    )

    return response.text, relevant_chunks, low_relevance_warning

def generate_example_questions(chunks, num_questions=4):
    """Genererar exempel fr친gor baserat p친 dokumentets inneh친ll."""
    # Ta ett sample av chunks f칬r att f친 en 칬verblick
    sample_size = min(10, len(chunks))
    sample_chunks = chunks[::len(chunks)//sample_size][:sample_size]
    sample_text = "\n\n".join(sample_chunks)

    # Begr칛nsa l칛ngden
    if len(sample_text) > 5000:
        sample_text = sample_text[:5000]

    prompt = f"""Baserat p친 f칬ljande textutdrag, generera {num_questions} intressanta och relevanta fr친gor som n친gon skulle kunna st칛lla om inneh친llet.

Regler:
- Fr친gorna ska vara specifika och relevanta f칬r texten
- Variera typen av fr친gor (vad, hur, varf칬r, etc.)
- G칬r fr친gorna koncisa (max 10-15 ord)
- Skriv ENDAST fr친gorna, en per rad, utan numrering eller punkter
- Svara p친 svenska

Text:
{sample_text}"""

    try:
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            config=genai.types.GenerateContentConfig(temperature=0.7),
            contents=prompt
        )

        # Dela upp i individuella fr친gor
        questions = [q.strip() for q in response.text.strip().split('\n') if q.strip() and '?' in q]
        return questions[:num_questions]
    except Exception as e:
        # Fallback om n친got g친r fel
        return [
            "Vad handlar dokumentet om?",
            "Kan du sammanfatta huvudpunkterna?",
            "Vilka 칛r de viktigaste begreppen?",
            "Finns det n친gra exempel i texten?"
        ]

# Streamlit UI
st.set_page_config(page_title="RAG Chattbot", page_icon="游늯")
st.title("RAG Chattbot")
st.write("Ladda upp en PDF eller klistra in en YouTube l칛nk och st칛ll fr친gor!")

# Sidebar f칬r k칛lla
with st.sidebar:
    st.header("V칛lj k칛lla")
    source_type = st.radio("Typ av k칛lla:", ["PDF", "YouTube"], horizontal=True)

    # Avancerade inst칛llningar
    st.divider()
    with st.expander("S칬kinst칛llningar"):
        relevance_threshold = st.slider(
            "Relevans tr칬skel",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.05,
            help="Minimum relevans f칬r att inkludera en k칛lla. H칬gre v칛rde = str칛ngare filter."
        )
        max_chunks = st.slider(
            "Max antal k칛llor",
            min_value=1,
            max_value=10,
            value=5,
            help="Max antal textdelar att anv칛nda f칬r att svara."
        )

    st.divider()

    if source_type == "PDF":
        uploaded_files = st.file_uploader("V칛lj PDF filer", type="pdf", accept_multiple_files=True)

        if uploaded_files:
            # Skapa en unik nyckel baserat p친 alla filnamn
            file_names = sorted([f.name for f in uploaded_files])
            files_key = "|".join(file_names)

            # Kolla om det 칛r nya filer
            if "current_source" not in st.session_state or st.session_state.current_source != files_key:
                with st.spinner(f"Bearbetar {len(uploaded_files)} PDF fil(er)..."):
                    # Rensa gamla data
                    st.session_state.chunks = None
                    st.session_state.embeddings = None
                    st.session_state.messages = []
                    st.session_state.current_source = files_key
                    st.session_state.source_type = "PDF"
                    st.session_state.file_names = file_names

                    # L칛s in alla PDF filer och samla metadata
                    all_text = ""
                    total_pages = 0
                    total_size = 0
                    file_info = []

                    for uploaded_file in uploaded_files:
                        reader = PdfReader(uploaded_file)
                        pages = len(reader.pages)
                        total_pages += pages
                        total_size += uploaded_file.size

                        file_text = ""
                        for page in reader.pages:
                            extracted = page.extract_text() or ""
                            # Fixa svenska tecken och normalisera
                            file_text += fix_swedish_chars(extracted)

                        file_info.append({
                            "name": uploaded_file.name,
                            "pages": pages,
                            "size": uploaded_file.size
                        })

                        all_text += file_text + "\n\n"

                    # Spara metadata
                    st.session_state.file_info = file_info
                    st.session_state.total_pages = total_pages
                    st.session_state.total_size = total_size
                    st.session_state.total_chars = len(all_text)
                    st.session_state.total_words = len(all_text.split())

                    # Chunka texten
                    st.session_state.chunks = chunk_text(all_text)

                    # Skapa embeddings
                    st.session_state.embeddings = create_embeddings(st.session_state.chunks)

                    # Generera exempel fr친gor
                    with st.spinner("Genererar exempel fr친gor..."):
                        st.session_state.example_questions = generate_example_questions(st.session_state.chunks)

                st.success(f"{len(uploaded_files)} PDF fil(er) laddade!")

            # Visa info om dokumenten
            st.divider()
            st.subheader("Dokumentinfo")

            # Visa varje fil med detaljer
            for info in st.session_state.get("file_info", []):
                size_kb = info["size"] / 1024
                st.markdown(f"**{info['name']}**")
                st.caption(f"{info['pages']} sidor | {size_kb:.1f} KB")

            # Sammanfattning
            st.divider()
            st.markdown("**Sammanfattning**")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Totalt sidor", st.session_state.get("total_pages", 0))
                st.metric("Chunks", len(st.session_state.chunks))
            with col2:
                st.metric("Ord", f"{st.session_state.get('total_words', 0):,}".replace(",", " "))
                size_mb = st.session_state.get("total_size", 0) / (1024 * 1024)
                st.metric("Storlek", f"{size_mb:.2f} MB")
        else:
            if "current_source" in st.session_state and st.session_state.get("source_type") == "PDF":
                st.session_state.clear()

    else:  # YouTube
        youtube_url = st.text_input("Klistra in YouTube l칛nk:", placeholder="https://www.youtube.com/watch?v=...")

        if st.button("Ladda video", type="primary"):
            if youtube_url:
                # Kolla om det 칛r en ny URL
                if "current_source" not in st.session_state or st.session_state.current_source != youtube_url:
                    with st.spinner("H칛mtar transkript fr친n YouTube..."):
                        try:
                            # Rensa gamla data
                            st.session_state.chunks = None
                            st.session_state.embeddings = None
                            st.session_state.messages = []
                            st.session_state.current_source = youtube_url
                            st.session_state.source_type = "YouTube"

                            # H칛mta transkript
                            text = get_youtube_transcript(youtube_url)

                            # Spara metadata om videon
                            video_id = extract_video_id(youtube_url)
                            st.session_state.video_id = video_id
                            st.session_state.transcript_chars = len(text)
                            st.session_state.transcript_words = len(text.split())

                            # Chunka texten
                            st.session_state.chunks = chunk_text(text)

                            # Skapa embeddings
                            st.session_state.embeddings = create_embeddings(st.session_state.chunks)

                            # Generera exempel fr친gor
                            with st.spinner("Genererar exempel-fr친gor..."):
                                st.session_state.example_questions = generate_example_questions(st.session_state.chunks)

                            st.success("YouTube-video laddad!")
                        except ValueError as e:
                            st.error(str(e))
            else:
                st.warning("Ange en YouTube l칛nk f칬rst!")

        # Visa info om videon om den 칛r laddad
        if st.session_state.get("source_type") == "YouTube" and st.session_state.get("chunks"):
            st.divider()
            st.subheader("Videoinfo")

            # Video-ID med l칛nk
            video_id = st.session_state.get("video_id", "")
            st.markdown(f"**Video-ID:** `{video_id}`")

            # Thumbnail
            if video_id:
                st.image(f"https://img.youtube.com/vi/{video_id}/mqdefault.jpg", use_container_width=True)

            # Statistik
            st.divider()
            st.markdown("**Transkript-statistik**")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Ord", f"{st.session_state.get('transcript_words', 0):,}".replace(",", " "))
                st.metric("Chunks", len(st.session_state.chunks))
            with col2:
                chars = st.session_state.get("transcript_chars", 0)
                st.metric("Tecken", f"{chars:,}".replace(",", " "))
                # Uppskattad l칛stid (ca 200 ord/min)
                words = st.session_state.get("transcript_words", 0)
                read_time = max(1, words // 200)
                st.metric("L칛stid", f"~{read_time} min")

# Initiera chatthistorik
if "messages" not in st.session_state:
    st.session_state.messages = []

# Visa chatthistorik
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "sources" in message:
            with st.expander("K칛llor som anv칛ndes"):
                for i, (chunk, score) in enumerate(message["sources"]):
                    # F칛rgkodning baserat p친 relevans
                    if score >= 0.75:
                        color = "游릭"  # Gr칬n - H칬g relevans
                    elif score >= 0.60:
                        color = "游리"  # Gul - Medel relevans
                    else:
                        color = "游댮"  # R칬d - L친g relevans

                    st.write(f"{color} **Chunk {i+1}** (relevans: {score:.2%})")
                    st.text(chunk[:300] + "..." if len(chunk) > 300 else chunk)
                    st.divider()

# Visa exempel fr친gor om det inte finns n친gra meddelanden 칛nnu
if st.session_state.get("chunks") is not None and len(st.session_state.messages) == 0:
    if "example_questions" in st.session_state and st.session_state.example_questions:
        st.markdown("### 游눬 F칬rslag p친 fr친gor")
        st.caption("Klicka p친 en fr친ga f칬r att st칛lla den:")

        # Visa fr친gor i kolumner (2 per rad)
        cols = st.columns(2)
        for idx, question in enumerate(st.session_state.example_questions):
            col = cols[idx % 2]
            with col:
                if st.button(question, key=f"example_q_{idx}", use_container_width=True):
                    # S칛tt fr친gan som n칛sta input
                    st.session_state.next_question = question
                    st.rerun()

# Chatt input
if st.session_state.get("chunks") is not None:
    source_label = "videon" if st.session_state.get("source_type") == "YouTube" else "dokumentet"

    # Visa alltid chat input
    user_input = st.chat_input(f"St칛ll en fr친ga om {source_label}...")

    # Kolla om det finns en fr친ga fr친n exempel knapp
    prompt = None
    if "next_question" in st.session_state:
        prompt = st.session_state.next_question
        del st.session_state.next_question
    elif user_input:
        prompt = user_input

    if prompt:
        # L칛gg till anv칛ndarens meddelande
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Generera svar
        with st.chat_message("assistant"):
            with st.spinner("T칛nker..."):
                response, sources, low_relevance = generate_response(
                    prompt,
                    st.session_state.chunks,
                    st.session_state.embeddings,
                    conversation_history=st.session_state.messages,
                    relevance_threshold=relevance_threshold,
                    max_chunks=max_chunks
                )

            # Visa varning om l친g relevans
            if low_relevance:
                st.warning("**L친g relevans**: Jag hittade ingen starkt relevant information f칬r din fr친ga. Svaret kan vara os칛kert.")

            st.markdown(response)

            # Visa k칛llor med f칛rgkodning
            with st.expander("K칛llor som anv칛ndes"):
                for i, (chunk, score) in enumerate(sources):
                    # F칛rgkodning baserat p친 relevans
                    if score >= 0.75:
                        color = "游릭"  # Gr칬n - H칬g relevans
                    elif score >= 0.60:
                        color = "游리"  # Gul - Medel relevans
                    else:
                        color = "游댮"  # R칬d - L친g relevans

                    st.write(f"{color} **Chunk {i+1}** (relevans: {score:.2%})")
                    st.text(chunk[:300] + "..." if len(chunk) > 300 else chunk)
                    st.divider()

        # Spara assistentens svar
        st.session_state.messages.append({
            "role": "assistant",
            "content": response,
            "sources": sources
        })
else:
    st.info("V칛lj en k칛lla i sidof칛ltet (PDF eller YouTube) f칬r att b칬rja!") 




# F칬rb칛ttringar:
# 1. Lagt till st칬d f칬r YouTube transkript som k칛lla.
# 2. Visar metadata om uppladdade PDF filer och YouTube videor.
# 3. Hanterar flera PDF filer samtidigt.
# 4. Fixade svenska tecken vid k칛llor fr친n ai svar.
# 5. Konversation historia, hanterar uppf칬ljningsfr친gor genom att inkludera tidigare konversation.
# 6. Relevans tr칬skel, filtrerar bort irrelevanta k칛llor och varnar vid l친g relevans.
# 7. F칛rgkodade relevans scores, visuell indikator f칬r k칛llornas relevans.
# 8. Justerbara s칬kinst칛llningar. Anv칛ndaren kan 칛ndra relevans tr칬skel och antal k칛llor.
# 9. Temperatur kontroll (0.3). Mer faktabaserade och mindre "kreativa" svar.
# 10. Exempel fr친gor, AI genererar automatiskt 4 relevanta fr친gor baserat p친 inneh친llet.

# Fr친gor:
# 1. Hur kan jag bek칛mpa prokrastinering n칛r jag ska l칛ra mig om AI?
# 2. Vilka tips finns om att l칛sa kurslitteratur och hur kan jag anv칛nda dem f칬r att f칬rst친 RAG-system?